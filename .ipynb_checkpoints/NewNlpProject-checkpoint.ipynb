{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9235159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c0972",
   "metadata": {},
   "source": [
    "# Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c066fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Train_Data.csv\")\n",
    "test_data=pd.read_csv(r\"C:\\Users\\Dell\\Downloads\\Test_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "fd4f229d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  cb774db0d1                I`d have responded, if I were going   \n",
       "1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2  088c60f138                          my boss is bullying me...   \n",
       "3  9642c003ef                     what interview! leave me alone   \n",
       "4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "\n",
       "                         selected_text sentiment  \n",
       "0  I`d have responded, if I were going   neutral  \n",
       "1                             Sooo SAD  negative  \n",
       "2                          bullying me  negative  \n",
       "3                       leave me alone  negative  \n",
       "4                        Sons of ****,  negative  "
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a02156f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textId</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4234ca4536</td>\n",
       "      <td>Lookin` at spreadsheets so long my eyes are cr...</td>\n",
       "      <td>my eyes are crossing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181bc1ee99</td>\n",
       "      <td>no way - those are great words.  Boys don`t g...</td>\n",
       "      <td>no way - those are great words.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee60f31d77</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9457c9ad0f</td>\n",
       "      <td>Word. Yayy twitter after dark lol.</td>\n",
       "      <td>. Yayy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64bce62</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textId                                               text  \\\n",
       "0  4234ca4536  Lookin` at spreadsheets so long my eyes are cr...   \n",
       "1  181bc1ee99   no way - those are great words.  Boys don`t g...   \n",
       "2  ee60f31d77         /drool. I still need to 100% the first one   \n",
       "3  9457c9ad0f                 Word. Yayy twitter after dark lol.   \n",
       "4  54f64bce62  So, #primavera is in Barcelona. In Spain. Sure...   \n",
       "\n",
       "                                       selected_text sentiment  \n",
       "0                            my eyes are crossing...  negative  \n",
       "1                    no way - those are great words.   neutral  \n",
       "2         /drool. I still need to 100% the first one   neutral  \n",
       "3                                             . Yayy  positive  \n",
       "4  So, #primavera is in Barcelona. In Spain. Sure...   neutral  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3f91d747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textId</th>\n",
       "      <th>tweet</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4234ca4536</td>\n",
       "      <td>Lookin` at spreadsheets so long my eyes are cr...</td>\n",
       "      <td>my eyes are crossing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181bc1ee99</td>\n",
       "      <td>no way - those are great words.  Boys don`t g...</td>\n",
       "      <td>no way - those are great words.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee60f31d77</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9457c9ad0f</td>\n",
       "      <td>Word. Yayy twitter after dark lol.</td>\n",
       "      <td>. Yayy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64bce62</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>6c86c96dbe</td>\n",
       "      <td>I`m missing one of my diamond earrings. This m...</td>\n",
       "      <td>I`m missing one of my diamond earrings. This m...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>fbfad74229</td>\n",
       "      <td>I love wearing my hood too, even though in Po...</td>\n",
       "      <td>I love wearing my hood too, even though in Por...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>948e5f7b25</td>\n",
       "      <td>Well I`m obsessed w/all of them - but I watch...</td>\n",
       "      <td>Well I`m obsessed w/all of them - but I watche...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>6021b57412</td>\n",
       "      <td>is this a new album?? about bloody time too!!</td>\n",
       "      <td>is this a new album?? about bloody time too!!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>fa78beca22</td>\n",
       "      <td>youre very welcome....you deserve it!!</td>\n",
       "      <td>welcome.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textId                                              tweet  \\\n",
       "0     4234ca4536  Lookin` at spreadsheets so long my eyes are cr...   \n",
       "1     181bc1ee99   no way - those are great words.  Boys don`t g...   \n",
       "2     ee60f31d77         /drool. I still need to 100% the first one   \n",
       "3     9457c9ad0f                 Word. Yayy twitter after dark lol.   \n",
       "4     54f64bce62  So, #primavera is in Barcelona. In Spain. Sure...   \n",
       "...          ...                                                ...   \n",
       "1996  6c86c96dbe  I`m missing one of my diamond earrings. This m...   \n",
       "1997  fbfad74229   I love wearing my hood too, even though in Po...   \n",
       "1998  948e5f7b25   Well I`m obsessed w/all of them - but I watch...   \n",
       "1999  6021b57412      is this a new album?? about bloody time too!!   \n",
       "2000  fa78beca22             youre very welcome....you deserve it!!   \n",
       "\n",
       "                                          selected_text sentiment  \n",
       "0                               my eyes are crossing...  negative  \n",
       "1                       no way - those are great words.   neutral  \n",
       "2            /drool. I still need to 100% the first one   neutral  \n",
       "3                                                . Yayy  positive  \n",
       "4     So, #primavera is in Barcelona. In Spain. Sure...   neutral  \n",
       "...                                                 ...       ...  \n",
       "1996  I`m missing one of my diamond earrings. This m...  negative  \n",
       "1997  I love wearing my hood too, even though in Por...   neutral  \n",
       "1998  Well I`m obsessed w/all of them - but I watche...   neutral  \n",
       "1999      is this a new album?? about bloody time too!!   neutral  \n",
       "2000                                           welcome.  positive  \n",
       "\n",
       "[2001 rows x 4 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def renameColumn(dataset):\n",
    "    dataset.rename(columns={'text':'tweet'},inplace=True)\n",
    "    return dataset\n",
    "renameColumn(train_data)\n",
    "renameColumn(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7cdb2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling_emotions={\"positive\" : 1 , \"negative\" : -1 , \"neutral\" : 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0c5b50ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textId</th>\n",
       "      <th>tweet</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4234ca4536</td>\n",
       "      <td>Lookin` at spreadsheets so long my eyes are cr...</td>\n",
       "      <td>my eyes are crossing...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181bc1ee99</td>\n",
       "      <td>no way - those are great words.  Boys don`t g...</td>\n",
       "      <td>no way - those are great words.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee60f31d77</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9457c9ad0f</td>\n",
       "      <td>Word. Yayy twitter after dark lol.</td>\n",
       "      <td>. Yayy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64bce62</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>6c86c96dbe</td>\n",
       "      <td>I`m missing one of my diamond earrings. This m...</td>\n",
       "      <td>I`m missing one of my diamond earrings. This m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>fbfad74229</td>\n",
       "      <td>I love wearing my hood too, even though in Po...</td>\n",
       "      <td>I love wearing my hood too, even though in Por...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>948e5f7b25</td>\n",
       "      <td>Well I`m obsessed w/all of them - but I watch...</td>\n",
       "      <td>Well I`m obsessed w/all of them - but I watche...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>6021b57412</td>\n",
       "      <td>is this a new album?? about bloody time too!!</td>\n",
       "      <td>is this a new album?? about bloody time too!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>fa78beca22</td>\n",
       "      <td>youre very welcome....you deserve it!!</td>\n",
       "      <td>welcome.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textId                                              tweet  \\\n",
       "0     4234ca4536  Lookin` at spreadsheets so long my eyes are cr...   \n",
       "1     181bc1ee99   no way - those are great words.  Boys don`t g...   \n",
       "2     ee60f31d77         /drool. I still need to 100% the first one   \n",
       "3     9457c9ad0f                 Word. Yayy twitter after dark lol.   \n",
       "4     54f64bce62  So, #primavera is in Barcelona. In Spain. Sure...   \n",
       "...          ...                                                ...   \n",
       "1996  6c86c96dbe  I`m missing one of my diamond earrings. This m...   \n",
       "1997  fbfad74229   I love wearing my hood too, even though in Po...   \n",
       "1998  948e5f7b25   Well I`m obsessed w/all of them - but I watch...   \n",
       "1999  6021b57412      is this a new album?? about bloody time too!!   \n",
       "2000  fa78beca22             youre very welcome....you deserve it!!   \n",
       "\n",
       "                                          selected_text  sentiment  \n",
       "0                               my eyes are crossing...         -1  \n",
       "1                       no way - those are great words.          0  \n",
       "2            /drool. I still need to 100% the first one          0  \n",
       "3                                                . Yayy          1  \n",
       "4     So, #primavera is in Barcelona. In Spain. Sure...          0  \n",
       "...                                                 ...        ...  \n",
       "1996  I`m missing one of my diamond earrings. This m...         -1  \n",
       "1997  I love wearing my hood too, even though in Por...          0  \n",
       "1998  Well I`m obsessed w/all of them - but I watche...          0  \n",
       "1999      is this a new album?? about bloody time too!!          0  \n",
       "2000                                           welcome.          1  \n",
       "\n",
       "[2001 rows x 4 columns]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labellingEmotions(dataset):\n",
    "    dataset.replace(labelling_emotions, inplace = True)\n",
    "    return dataset\n",
    "labellingEmotions(train_data)\n",
    "labellingEmotions(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7063ac",
   "metadata": {},
   "source": [
    "# Dropping Unwanted Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "a31bf0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textId</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4234ca4536</td>\n",
       "      <td>Lookin` at spreadsheets so long my eyes are cr...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181bc1ee99</td>\n",
       "      <td>no way - those are great words.  Boys don`t g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ee60f31d77</td>\n",
       "      <td>/drool. I still need to 100% the first one</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9457c9ad0f</td>\n",
       "      <td>Word. Yayy twitter after dark lol.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54f64bce62</td>\n",
       "      <td>So, #primavera is in Barcelona. In Spain. Sure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>6c86c96dbe</td>\n",
       "      <td>I`m missing one of my diamond earrings. This m...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>fbfad74229</td>\n",
       "      <td>I love wearing my hood too, even though in Po...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>948e5f7b25</td>\n",
       "      <td>Well I`m obsessed w/all of them - but I watch...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>6021b57412</td>\n",
       "      <td>is this a new album?? about bloody time too!!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>fa78beca22</td>\n",
       "      <td>youre very welcome....you deserve it!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2001 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textId                                              tweet  sentiment\n",
       "0     4234ca4536  Lookin` at spreadsheets so long my eyes are cr...         -1\n",
       "1     181bc1ee99   no way - those are great words.  Boys don`t g...          0\n",
       "2     ee60f31d77         /drool. I still need to 100% the first one          0\n",
       "3     9457c9ad0f                 Word. Yayy twitter after dark lol.          1\n",
       "4     54f64bce62  So, #primavera is in Barcelona. In Spain. Sure...          0\n",
       "...          ...                                                ...        ...\n",
       "1996  6c86c96dbe  I`m missing one of my diamond earrings. This m...         -1\n",
       "1997  fbfad74229   I love wearing my hood too, even though in Po...          0\n",
       "1998  948e5f7b25   Well I`m obsessed w/all of them - but I watch...          0\n",
       "1999  6021b57412      is this a new album?? about bloody time too!!          0\n",
       "2000  fa78beca22             youre very welcome....you deserve it!!          1\n",
       "\n",
       "[2001 rows x 3 columns]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_drop=['selected_text']\n",
    "train_data.drop(columns=columns_drop)\n",
    "test_data.drop(columns=columns_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7572a42",
   "metadata": {},
   "source": [
    "# Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "3e6eca65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     i`d have responded, if i were going\n",
      "1           sooo sad i will miss you here in san diego!!!\n",
      "2                               my boss is bullying me...\n",
      "3                          what interview! leave me alone\n",
      "4        sons of ****, why couldn`t they put them on t...\n",
      "                              ...                        \n",
      "9994                                            im 16 too\n",
      "9995                   just got bullied by dillah.  help!\n",
      "9996                                            what lol?\n",
      "9997     some days you must look hard for that good th...\n",
      "9998    i`m so worn out, this week has sped by soo fas...\n",
      "Name: tweet, Length: 9999, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data['tweet'] = train_data['tweet'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "test_data['tweet'] = test_data['tweet'].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "\n",
    "print(train_data['tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166c804e",
   "metadata": {},
   "source": [
    "# Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4682aac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Sentences:\n",
      "          textID                                        tweet  \\\n",
      "95    4c41a35a2a  happy mothers day to all you mums out there   \n",
      "170   f3d95b57b1                                 good morning   \n",
      "1139  cd1a90193c                           happy mothers day!   \n",
      "1387  d0ab385860                                       thanks   \n",
      "1643  608497a8e5                                   thank you.   \n",
      "1788  eeeea78845                                 good morning   \n",
      "2175  5047df4e16                                       thanks   \n",
      "2354  930b5a21be                                  tummy hurts   \n",
      "2408  ef9483e22e                                 good morning   \n",
      "2932  b30b858bfc                                    thank you   \n",
      "3274  3f8a34153b                                    thank you   \n",
      "3975  655659de18                           happy mothers day!   \n",
      "4114  d7f6f40f36                                 good morning   \n",
      "4413  77a183021d                               i miss you too   \n",
      "6532  e73ed8a847                               i miss you too   \n",
      "7424  433cb03f2a                                  tummy hurts   \n",
      "8292  24e37fce8c  happy mothers day to all you mums out there   \n",
      "8896  9d5cfa4d06                                       thanks   \n",
      "9409  bb6edcc1b8                                   thank you.   \n",
      "\n",
      "                                    selected_text  sentiment  \n",
      "95    Happy Mothers day to all you Mums out there          1  \n",
      "170                                  good morning          1  \n",
      "1139                           Happy Mothers Day!          1  \n",
      "1387                                       Thanks          1  \n",
      "1643                                   thank you.          1  \n",
      "1788                                         Good          1  \n",
      "2175                                       thanks          1  \n",
      "2354                                  Tummy hurts         -1  \n",
      "2408                                 good morning          1  \n",
      "2932                                    Thank you          1  \n",
      "3274                                    thank you          1  \n",
      "3975                           HAPPY MOTHERS DAY!          1  \n",
      "4114                                 Good Morning          1  \n",
      "4413                               i miss you too         -1  \n",
      "6532                               I miss you too         -1  \n",
      "7424                                  tummy hurts         -1  \n",
      "8292                                        happy         -1  \n",
      "8896                                       THANKS          1  \n",
      "9409                                   Thank you.          1  \n",
      "Empty DataFrame\n",
      "Columns: [textId, tweet, selected_text, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates1 = train_data[train_data['tweet'].duplicated(keep=False)]\n",
    "duplicates2 = test_data[test_data['tweet'].duplicated(keep=False)]\n",
    "print(\"Duplicated Sentences:\")\n",
    "print(duplicates1)\n",
    "print(duplicates2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d842cd38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                     i`d have responded, if i were going\n",
      "1           sooo sad i will miss you here in san diego!!!\n",
      "2                               my boss is bullying me...\n",
      "3                          what interview! leave me alone\n",
      "4        sons of ****, why couldn`t they put them on t...\n",
      "                              ...                        \n",
      "9994                                            im 16 too\n",
      "9995                   just got bullied by dillah.  help!\n",
      "9996                                            what lol?\n",
      "9997     some days you must look hard for that good th...\n",
      "9998    i`m so worn out, this week has sped by soo fas...\n",
      "Name: tweet, Length: 9989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_data.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
    "test_data.drop_duplicates(subset='tweet', keep='first', inplace=True)\n",
    "print(train_data['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "f6699710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated Sentences:\n",
      "Empty DataFrame\n",
      "Columns: [textID, tweet, selected_text, sentiment]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "duplicates = train_data[train_data['tweet'].duplicated(keep=False)]\n",
    "\n",
    "print(\"Duplicated Sentences:\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274dd251",
   "metadata": {},
   "source": [
    "# Removing appostrophies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "abb90379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                 i would have responded, if i were going\n",
      "1           sooo sad i will miss you here in san diego!!!\n",
      "2                               my boss is bullying me...\n",
      "3                          what interview! leave me alone\n",
      "4       sons of ****, why could not they put them on t...\n",
      "                              ...                        \n",
      "9994                                          i am 16 too\n",
      "9995                    just got bullied by dillah. help!\n",
      "9996                                            what lol?\n",
      "9997    some days you must look hard for that good thing.\n",
      "9998    i am so worn out, this week has sped by soo fa...\n",
      "Name: tokenized_tweet, Length: 9989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "appostrophy_dict = {\n",
    "    \"can`t\": \"cannot\",\n",
    "    \"cant\": \"cannot\",\n",
    "    \"aren`t\": \"are not\",\n",
    "    \"arent\": \"are not\",\n",
    "    \"couldn`t\": \"could not\",\n",
    "    \"couldnt\": \"could not\",\n",
    "    \"doesn`t\": \"does not\",\n",
    "    \"doesnt\": \"does not\",\n",
    "    \"don`t\": \"do not\",\n",
    "    \"dont\": \"do not\",\n",
    "    \"hadn`t\": \"had not\",\n",
    "    \"hadnt\": \"had not\",\n",
    "    \"hasn`t\": \"has not\",\n",
    "    \"hasnt\": \"has not\",\n",
    "    \"haven`t\": \"have not\",\n",
    "    \"havent\": \"have not\",\n",
    "    \"he`d\": \"he would\",\n",
    "    \"he`ll\": \"he will\",\n",
    "    \"he`s\": \"he is\",\n",
    "    \"i`d\": \"i would\",\n",
    "    \"i`ll\": \"I will\",\n",
    "    \"i`m\": \"i am\",\n",
    "    \"im\": \"i am\",\n",
    "    \"isn`t\": \"is not\",\n",
    "    \"isnt\": \"is not\",\n",
    "    \"it`s\": \"it is\",\n",
    "    \"it`ll\": \"it will\",\n",
    "    \"i`ve\": \"i have\",\n",
    "    \"let`s\": \"let us\",\n",
    "    \"mightn`t\": \"might not\",\n",
    "    \"mightnt\": \"might not\",\n",
    "    \"mustn`t\": \"must not\",\n",
    "    \"mustnt\": \"must not\",\n",
    "    \"shan`t\": \"shall not\",\n",
    "    \"she`d\": \"she would\",\n",
    "    \"she`ll\": \"she will\",\n",
    "    \"she`s\": \"she is\",\n",
    "    \"shouldn`t\": \"should not\",\n",
    "    \"shouldnt\": \"should not\",\n",
    "    \"that`s\": \"that is\",\n",
    "    \"thats\": \"that is\",\n",
    "    \"there`s\": \"there is\",\n",
    "    \"they`d\": \"they would\",\n",
    "    \"they`ll\": \"they will\",\n",
    "    \"they`re\": \"they are\",\n",
    "    \"they`ve\": \"they have\",\n",
    "    \"we`d\": \"we would\",\n",
    "    \"we`re\": \"we are\",\n",
    "    \"weren`t\": \"were not\",\n",
    "    \"we`ve\": \"we have\",\n",
    "    \"what`ll\": \"what will\",\n",
    "    \"what`re\": \"what are\",\n",
    "    \"what`s\": \"what is\",\n",
    "    \"whats\": \"what is\",\n",
    "    \"what`ve\": \"what have\",\n",
    "    \"where`s\": \"where is\",\n",
    "    \"who`d\": \"who would\",\n",
    "    \"who`ll\": \"who will\",\n",
    "    \"who`re\": \"who are\",\n",
    "    \"who`s\": \"who is\",\n",
    "    \"who`ve\": \"who have\",\n",
    "    \"won`t\": \"will not\",\n",
    "    \"wont\": \"will not\",\n",
    "    \"wouldn`t\": \"would not\",\n",
    "    \"wouldnt\": \"would not\",\n",
    "    \"you`d\": \"you would\",\n",
    "    \"you`ll\": \"you will\",\n",
    "    \"you`re\": \"you are\",\n",
    "    \"you`ve\": \"you have\",\n",
    "    \"wasn`t\": \"was not\",\n",
    "    \"wasnt\": \"was not\",\n",
    "    \"we`ll\": \"will\",\n",
    "    \"didn`t\": \"did not\",\n",
    "    \"didnt\": \"did not\"\n",
    "}\n",
    "\n",
    "def removingAppostrophies(tokens):\n",
    "    if tokens is not None:\n",
    "        removedText = []\n",
    "        for token in tokens:\n",
    "            token_lower = token.lower()\n",
    "            if token_lower.endswith(\"`s\"):\n",
    "                removedText.append(token_lower[:-2] + \" is\")\n",
    "            elif token_lower in appostrophy_dict:\n",
    "                removedText.append(appostrophy_dict[token_lower])\n",
    "            else:\n",
    "                removedText.append(token)\n",
    "        value = \" \".join(removedText)\n",
    "        return value\n",
    "\n",
    "train_data['tokenized_tweet'] = train_data['tweet'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "train_data['tokenized_tweet'] = train_data['tokenized_tweet'].apply(removingAppostrophies)\n",
    "\n",
    "\n",
    "print(train_data['tokenized_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae39b02",
   "metadata": {},
   "source": [
    "# Removing Punctuations and tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "5f612b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [i, would, have, responded, if, i, were, going]\n",
      "1       [sooo, sad, i, will, miss, you, here, in, san,...\n",
      "2                            [my, boss, is, bullying, me]\n",
      "3                     [what, interview, leave, me, alone]\n",
      "4       [sons, of, why, could, not, they, put, them, o...\n",
      "                              ...                        \n",
      "9994                                     [i, am, 16, too]\n",
      "9995               [just, got, bullied, by, dillah, help]\n",
      "9996                                          [what, lol]\n",
      "9997    [some, days, you, must, look, hard, for, that,...\n",
      "9998    [i, am, so, worn, out, this, week, has, sped, ...\n",
      "Name: tokenized_tweet, Length: 9989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def tokenization(text):\n",
    "\n",
    "    punctuation = '!\"$%&\\()*+,-./:;<=>?[\\\\]^_`{|}~'\n",
    "    if isinstance(text, str):\n",
    "        for char in punctuation:\n",
    "            text = text.replace(char, ' ')\n",
    "        tokens = text.split()\n",
    "\n",
    "        return tokens\n",
    "\n",
    "train_data['tokenized_tweet']=train_data['tokenized_tweet'].apply(tokenization)\n",
    "print(train_data['tokenized_tweet'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a6a8e4",
   "metadata": {},
   "source": [
    "# Removing Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "e56e3cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         [i, would, have, responded, if, i, were, going]\n",
      "1       [sooo, sad, i, will, miss, you, here, in, san,...\n",
      "2                            [my, boss, is, bullying, me]\n",
      "3                     [what, interview, leave, me, alone]\n",
      "4       [sons, of, why, could, not, they, put, them, o...\n",
      "                              ...                        \n",
      "9994                                         [i, am, too]\n",
      "9995               [just, got, bullied, by, dillah, help]\n",
      "9996                                          [what, lol]\n",
      "9997    [some, days, you, must, look, hard, for, that,...\n",
      "9998    [i, am, so, worn, out, this, week, has, sped, ...\n",
      "Name: tokenized_tweet, Length: 9989, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def RemovingNumbers(tokens):\n",
    "    if tokens is None:\n",
    "        return []\n",
    "    else:\n",
    "        pattern = r'\\b\\w*\\d\\w*\\b'\n",
    "        removingNumbers_tokens = [token for token in tokens if not re.search(pattern, token)]\n",
    "        return removingNumbers_tokens\n",
    "\n",
    " \n",
    "train_data[\"tokenized_tweet\"] = train_data[\"tokenized_tweet\"].apply(RemovingNumbers)\n",
    "print(train_data[\"tokenized_tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ce9d5996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>tweet</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>i`d have responded, if i were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, would, have, responded, if, i, were, going]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>sooo sad i will miss you here in san diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>-1</td>\n",
       "      <td>[sooo, sad, i, will, miss, you, here, in, san,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>-1</td>\n",
       "      <td>[my, boss, is, bullying, me]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>-1</td>\n",
       "      <td>[what, interview, leave, me, alone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>-1</td>\n",
       "      <td>[sons, of, why, could, not, they, put, them, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4c41a35a2a</td>\n",
       "      <td>happy mothers day to all you mums out there</td>\n",
       "      <td>Happy Mothers day to all you Mums out there</td>\n",
       "      <td>1</td>\n",
       "      <td>[happy, mothers, day, to, all, you, mums, out,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>61a8e11e8a</td>\n",
       "      <td>casey`s gone?!?! but why?! so, she piddled a ...</td>\n",
       "      <td>freaked</td>\n",
       "      <td>-1</td>\n",
       "      <td>[casey, is, gone, but, why, so, she, piddled, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>447dc22c81</td>\n",
       "      <td>hemp cloth is marvelous but unfortunately no</td>\n",
       "      <td>unfortunately</td>\n",
       "      <td>-1</td>\n",
       "      <td>[hemp, cloth, is, marvelous, but, unfortunatel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3408db03a3</td>\n",
       "      <td>gonna read a story bout adam lambert online th...</td>\n",
       "      <td>Gonna read a story bout adam lambert online th...</td>\n",
       "      <td>0</td>\n",
       "      <td>[gonna, read, a, story, bout, adam, lambert, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>92e1b6846e</td>\n",
       "      <td>we saw that in none 3d - the baddie`s the best</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>[we, saw, that, in, none, the, baddie, is, the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                              tweet  \\\n",
       "0   cb774db0d1                i`d have responded, if i were going   \n",
       "1   549e992a42      sooo sad i will miss you here in san diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   sons of ****, why couldn`t they put them on t...   \n",
       "..         ...                                                ...   \n",
       "95  4c41a35a2a        happy mothers day to all you mums out there   \n",
       "96  61a8e11e8a   casey`s gone?!?! but why?! so, she piddled a ...   \n",
       "97  447dc22c81       hemp cloth is marvelous but unfortunately no   \n",
       "98  3408db03a3  gonna read a story bout adam lambert online th...   \n",
       "99  92e1b6846e     we saw that in none 3d - the baddie`s the best   \n",
       "\n",
       "                                        selected_text  sentiment  \\\n",
       "0                 I`d have responded, if I were going          0   \n",
       "1                                            Sooo SAD         -1   \n",
       "2                                         bullying me         -1   \n",
       "3                                      leave me alone         -1   \n",
       "4                                       Sons of ****,         -1   \n",
       "..                                                ...        ...   \n",
       "95        Happy Mothers day to all you Mums out there          1   \n",
       "96                                            freaked         -1   \n",
       "97                                      unfortunately         -1   \n",
       "98  Gonna read a story bout adam lambert online th...          0   \n",
       "99                                               best          1   \n",
       "\n",
       "                                      tokenized_tweet  \n",
       "0     [i, would, have, responded, if, i, were, going]  \n",
       "1   [sooo, sad, i, will, miss, you, here, in, san,...  \n",
       "2                        [my, boss, is, bullying, me]  \n",
       "3                 [what, interview, leave, me, alone]  \n",
       "4   [sons, of, why, could, not, they, put, them, o...  \n",
       "..                                                ...  \n",
       "95  [happy, mothers, day, to, all, you, mums, out,...  \n",
       "96  [casey, is, gone, but, why, so, she, piddled, ...  \n",
       "97  [hemp, cloth, is, marvelous, but, unfortunatel...  \n",
       "98  [gonna, read, a, story, bout, adam, lambert, o...  \n",
       "99  [we, saw, that, in, none, the, baddie, is, the...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be3dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
